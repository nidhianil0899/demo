1. Difference between Block storage & Object Storage ?
Ans: Block storage will take any file apart into individual data blocks. 
It stores the blocks like data's separated pieces. All data's pieces contain the distinct address. Hence it does not require being stored within any file structure.
Object storage will take data's each piece and makes it as any object. Data will be stored in the isolated storehouses. It is bundled with related metadata and a specific identifier.

2. Difference between static website & dynamic website ?
Ans: On a static website, individual webpages include static content. They might also contain client-side scripts. By contrast, a dynamic website relies on server-side processing.

3. What are the naming rules ?
Ans: Be unique within the chosen AWS Region and Availability Zone.
Be no more than 3â€“63 characters long, including the suffix.
Consists only of lowercase letters, numbers and hyphens (-).
Begin and end with a letter or number.
Cannot be formatted as an IP address (e.g., 192.168.0.1).

4. What is the major resource of S3 Bucket ?
Ans:The major resource of an S3 bucket is Simple Storage Service, it provide scalable object storage for various types of data, such as images, videos, documents, backups
and application data.

5. Why do we need to host static websites instead of dynamic websites ?
Ans: Advantages over hosting dynamic websites are as follows:-
Cost-effectiveness: Static websites typically require fewer resources to host compared to dynamic websites.
Simplicity: Static websites are simpler to set up and maintain compared to dynamic websites. 
Performance: Static websites served through a CDN like CloudFront benefit from edge caching, which helps reduce latency and improve performance for users accessing
the website from different geographic locations.

6. What is versioning & Why do we need versioning ?
Ans: Versioning in AWS refers to the feature provided by services like Amazon S3, which allows you to keep multiple versions of an object 
(such as files or data) in the same bucket.
When versioning is enabled for an S3 bucket, every time you upload, copy, or delete an object, a new version of that object is created instead of overwriting the existing version.
Data protection and recovery: Versioning helps protect your data from accidental deletion or overwrites.
Immutable storage/ Unchanging storage: With versioning enabled, object versions in S3 are immutable/unchangable by default.
Rollbacks and experimentation: Versioning enables you to experiment with changes to objects without the risk of permanently altering or losing data. 

7. What are the objects and types of objects that we are uploading into the S3 Bucket ?
Ans: An object is a fundamental storage unit that contains data and metadata.
When you upload data to an S3 bucket, you are essentially uploading objects.
Some common types of objects that are uploaded into S3 buckets in AWS:
Files:  Files can include documents, images, videos, audio files, archives, logs, configuration files, etc. 
HTML Pages, Binary Data,Database Backups,Log Files
Machine Images: Images of virtual machines or servers (e.g., Amazon Machine Images - AMIs) 
can be uploaded as objects to S3 for creating EC2 instances or for sharing with other AWS accounts.

8. Why is MFA Delete important in S3 Bucket object level ?
Ans: Prevention of Accidental Deletion: MFA Delete helps prevent accidental deletion of objects by requiring an additional authentication factor.
Enhanced Security, Disaster Recovery and Backup

9. What is S3 Multipart upload ?
Ans: S3 Multipart Upload is a feature provided by Amazon S3 (Simple Storage Service) that allows you to upload large objects in parts, 
or chunks, instead of uploading the entire object in a single request. 
This feature is particularly useful for uploading very large files (typically those larger than 100 MB) 
or in situations where network instability or interruptions may occur during the upload process.

10. What are the storage classes in Amazon S3 ?
Ans: Standard: Amazon S3 Standard is the default storage class, offering high durability, availability, and performance for frequently accessed data.
It is designed for use cases where data needs to be readily accessible with low latency.
Standard-IA (Infrequent Access): Amazon S3 Standard-IA is designed for data that is accessed less frequently but requires rapid access when needed.
It offers the same performance and durability as Amazon S3 Standard but at a lower storage price and a higher retrieval fee.
One Zone-IA (Infrequent Access): One Zone-IA is similar to Standard-IA but stores data in a single Availability Zone instead of replicating it across multiple Availability Zones within a region.
Intelligent-Tiering: Intelligent-Tiering is a storage class that automatically moves objects between two access tiers: frequent access and infrequent access. 
It is designed to optimize storage costs by automatically selecting the appropriate tier based on usage patterns.
Glacier: Glacier is a low-cost archival storage class for data that is accessed infrequently and can tolerate retrieval times of several hours.
It offers significantly lower storage costs compared to other storage classes but incurs additional retrieval fees and longer retrieval times.
Glacier Deep Archive: Glacier Deep Archive is the lowest-cost storage class offered by Amazon S3, designed for long-term retention of data that is accessed very rarely,
with retrieval times of up to 12 hours. 
S3 Outposts: S3 Outposts storage classes allow you to store and retrieve data on-premises using AWS Outposts, extending the benefits of Amazon S3 storage classes to your on-premises environment.

11. What is ACL ?
Ans: ACL stands for Access Control List. 
An ACL is a set of rules that define permissions granted to users, groups, or other entities for accessing and performing operations on AWS resources such as S3 buckets and objects. 
These permissions can include read, write, delete, and list operations, among others.
In Amazon S3, ACLs can be applied at both the bucket level and the object level. There are three types of ACLs in Amazon S3:
Bucket ACLs
Object ACLs
Bucket Policies

12. Why do we need ACL ?
Ans: Security: ACLs allow you to control who has access to your resources and what actions they can perform. 
You can limit access to only authorized users or applications, reducing the risk of unauthorized access and data breaches.
Data Privacy: ACLs help protect sensitive or confidential data by restricting access to only those individuals or 
entities that need it to perform their job responsibilities.
Resource Management: ACLs enable organizations to manage resources effectively by defining access permissions based on roles, responsibilities,
or project requirements.
Customization: ACLs provide flexibility to customize access permissions based on specific use cases or business requirements. 
Auditing and Accountability: ACLs facilitate auditing and accountability by allowing organizations to track access to resources and monitor user activity. 

13. What is a Life cycle policy ? Why do we need to use the life cycle rule ?
Ans: A lifecycle policy, also known as a lifecycle rule,is a feature provided by Amazon S3  that allows you to define rules to automatically manage the lifecycle of objects stored in S3 buckets.
These rules specify actions to be taken on objects based on predefined criteria such as their age, size, or storage class.
The primary purpose of using a lifecycle policy is to automate the management of object storage and reduce storage costs by moving or deleting objects as they age or become less frequently accessed.
Cost Optimization: Lifecycle policies help optimize storage costs by automatically transitioning objects to lower-cost storage classes or deleting them when they are no longer needed. 
Performance: Lifecycle policies can improve performance by moving objects to storage classes that are optimized for specific access patterns. 
Data Security: Lifecycle policies can help improve data security by automatically deleting or moving sensitive or outdated data to secure storage classes or archival solutions. 

14. How can we make our bucket public ?
Ans: To make an Amazon S3 bucket public and allow public access to its contents, you need to configure the bucket's permissions appropriately. 
Making a bucket public means that anyone on the internet can access the objects stored in the bucket without authentication.


15.
Ans:

16.
Ans:

17.
Ans:

18.
Ans:

19.
Ans:

20.
Ans:

21.
Ans:

22.
Ans:
